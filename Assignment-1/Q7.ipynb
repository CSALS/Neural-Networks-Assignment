{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression for Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "#only for jupyter notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet = 'data3.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#header = None states that there is no header row or else it would take first row of our data as header.\n",
    "df = pd.read_excel(dataSet,sheet_name='Sheet1',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 1)\n"
     ]
    }
   ],
   "source": [
    "valueArray = df.to_numpy()\n",
    "np.random.shuffle(valueArray)\n",
    "#Hold out cross validation technique 60 - 40\n",
    "trainData , testData = valueArray[0:60,0:] , valueArray[60:,0:]\n",
    "X_train , y_train  = trainData[0:,0:4] , trainData[0:,4:]\n",
    "X_test , y_test = testData[0:,0:4] , testData[0:,4:]\n",
    "y_train = y_train - 1\n",
    "y_test = y_test -1\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the binary classifier using X_train and y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1.0/ (1.0 + math.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypothesis(X,w,bias):\n",
    "    sum = 0.0\n",
    "    for index_feature,feature in enumerate(X):\n",
    "        sum += w[index_feature][0] * feature\n",
    "    sum += bias\n",
    "    return sigmoid(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(X,y,index_feature,w,bias):\n",
    "    grad = 0.0\n",
    "    if index_feature == -1 :\n",
    "        #find gradient for bias\n",
    "        for index in range(X.shape[0]):\n",
    "            grad += (hypothesis(X[index],w,bias) - y[index][0])\n",
    "    else:\n",
    "        #find gradient for w[index][0]\n",
    "        for index in range(X.shape[0]):\n",
    "            grad += (hypothesis(X[index],w,bias) - y[index][0]) * X[index][index_feature]\n",
    "            \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticRegression(X,y,w,bias,alpha,iterations):\n",
    "    for index in range(iterations):\n",
    "        #update 4 weights and bias\n",
    "        #w = w - alpha/m * gradient\n",
    "        m = X.shape[0]\n",
    "        w0 = w[0][0] - (alpha/m) * gradient(X,y,0,w,bias)\n",
    "        w1 = w[1][0] - (alpha/m) * gradient(X,y,1,w,bias)\n",
    "        w2 = w[2][0] - (alpha/m) * gradient(X,y,2,w,bias)\n",
    "        w3 = w[3][0] - (alpha/m) * gradient(X,y,3,w,bias)\n",
    "        b  = bias - (alpha/m) * gradient(X,y,-1,w,bias)\n",
    "        w[0][0] = w0\n",
    "        w[1][0] = w1\n",
    "        w[2][0] = w2\n",
    "        w[3][0] = w3\n",
    "        bias = b\n",
    "    return [w,bias]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.17022005e-01]\n",
      " [7.20324493e-01]\n",
      " [1.14374817e-04]\n",
      " [3.02332573e-01]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1) \n",
    "w = np.random.rand(4,1) #Weight matrix with random values 4*1 matrix\n",
    "bias = 1\n",
    "#print(w,bias)\n",
    "w[0][0] = 4.17022005e-01\n",
    "w[1][0] = 7.20324493e-01\n",
    "w[2][0] = 1.14374817e-04\n",
    "w[3][0] = 3.02332573e-01\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = logisticRegression(X_train,y_train,w,bias,0.5,100)\n",
    "w = parameters[0]\n",
    "bias = parameters[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.7745544 ],\n",
       "       [-1.67418221],\n",
       "       [ 2.7840963 ],\n",
       "       [ 1.54966892]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5430265815983963"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the performance of binary classifier using X_test , y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nConfusion Matrix\\n\\nActual Output   Predicted Output\\n\\n                class 2 | class 1\\nclass 2         TN      |   FP\\n________________________|____________\\n                        |\\nclass 1         FN      |   TP\\n\\n'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Confusion Matrix\n",
    "\n",
    "Actual Output   Predicted Output\n",
    "\n",
    "                class 2 | class 1\n",
    "class 2         TN      |   FP\n",
    "________________________|____________\n",
    "                        |\n",
    "class 1         FN      |   TP\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Predicting output based on our trained classifier\n",
    "If signmoid >= 0.5 then it belongs to class 2 else class 1\n",
    "\"\"\"\n",
    "y_predicted = []\n",
    "for index in range(X_test.shape[0]):\n",
    "    x = X_test[index]\n",
    "    h = hypothesis(x,w,bias)\n",
    "    if h >= 0.5:\n",
    "        y_predicted.append(1)\n",
    "    else:\n",
    "        y_predicted.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix -> \n",
      "20   0\n",
      "0   20\n"
     ]
    }
   ],
   "source": [
    "trueNegatives = truePositives = falsePositives = falseNegatives = 0\n",
    "for index in range(y_test.shape[0]):\n",
    "    if y_test[index][0] == 1 :\n",
    "        if y_predicted[index] == 1 :\n",
    "            trueNegatives += 1\n",
    "        else :\n",
    "            falsePositives += 1\n",
    "    else :\n",
    "        if y_predicted[index] == 0:\n",
    "            truePositives += 1\n",
    "        else :\n",
    "            falseNegatives += 1\n",
    "print(\"Confusion Matrix -> \")\n",
    "print(trueNegatives,\" \",falsePositives)\n",
    "print(falseNegatives,\" \",truePositives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sensitivity = TP(TP + FN)\n",
    "SE = float(truePositives)/float(truePositives + falseNegatives)\n",
    "#Specificity = TN(TN + FP)\n",
    "SP = float(trueNegatives)/float(trueNegatives + falsePositives)\n",
    "#Accuracy = (TP + TN)/(TP + TN + FP + FN)\n",
    "Acc = float(truePositives + trueNegatives)/float(trueNegatives + truePositives + falsePositives + falseNegatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity is :  100.0 %\n",
      "Specificity is :  100.0 %\n",
      "Accuracy is :  100.0 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Sensitivity is : \",SE*100,\"%\")\n",
    "print(\"Specificity is : \",SP*100,\"%\")\n",
    "print(\"Accuracy is : \",Acc*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
