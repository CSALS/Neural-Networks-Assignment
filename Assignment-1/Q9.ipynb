{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multiclass Logistic Regression using 5 fold cross validation technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "#only for jupyter notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet = 'data4.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#header = None states that there is no header row or else it would take first row of our data as header.\n",
    "df = pd.read_excel(dataSet,sheet_name='Sheet1',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n5 fold cross validation ->\\n\\n150 points / 5 = 30 points in each of 5 subsets\\n\\nloop(5 times) ->\\n    choose one subset as testing and remaining 4 for training\\n    run the logistic regression and test on the one testing subset\\n'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "5 fold cross validation ->\n",
    "\n",
    "150 points / 5 = 30 points in each of 5 subsets\n",
    "\n",
    "loop(5 times) ->\n",
    "    choose one subset as testing and remaining 4 for training\n",
    "    run the logistic regression and test on the one testing subset\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Binary Logistic Regression -> classifies between 1 and 0\n",
    "def sigmoid(z):\n",
    "    return 1.0/ (1.0 + math.exp(-z))\n",
    "\n",
    "def hypothesis(X,w,bias):\n",
    "    sum = 0.0\n",
    "    for index_feature,feature in enumerate(X):\n",
    "        sum += w[index_feature][0] * feature\n",
    "    sum += bias\n",
    "    return sigmoid(sum)\n",
    "\n",
    "def gradient(X,y,index_feature,w,bias):\n",
    "    grad = 0.0\n",
    "    if index_feature == -1 :\n",
    "        #find gradient for bias\n",
    "        for index in range(X.shape[0]):\n",
    "            grad += (hypothesis(X[index],w,bias) - y[index][0])\n",
    "    else:\n",
    "        #find gradient for w[index][0]\n",
    "        for index in range(X.shape[0]):\n",
    "            grad += (hypothesis(X[index],w,bias) - y[index][0]) * X[index][index_feature]\n",
    "            \n",
    "    return grad\n",
    "\n",
    "def logisticRegression(X,y,w,bias,alpha,iterations):\n",
    "    for index in range(iterations):\n",
    "        #update 7 weights and bias\n",
    "        #w = w - alpha/m * gradient\n",
    "        m = X.shape[0]\n",
    "        w0 = w[0][0] - (alpha/m) * gradient(X,y,0,w,bias)\n",
    "        w1 = w[1][0] - (alpha/m) * gradient(X,y,1,w,bias)\n",
    "        w2 = w[2][0] - (alpha/m) * gradient(X,y,2,w,bias)\n",
    "        w3 = w[3][0] - (alpha/m) * gradient(X,y,3,w,bias)\n",
    "        w4 = w[4][0] - (alpha/m) * gradient(X,y,4,w,bias)\n",
    "        w5 = w[5][0] - (alpha/m) * gradient(X,y,5,w,bias)\n",
    "        w6 = w[6][0] - (alpha/m) * gradient(X,y,6,w,bias)\n",
    "        b  = bias - (alpha/m) * gradient(X,y,-1,w,bias)\n",
    "        w[0][0] = w0\n",
    "        w[1][0] = w1\n",
    "        w[2][0] = w2\n",
    "        w[3][0] = w3\n",
    "        w[4][0] = w4\n",
    "        w[5][0] = w5\n",
    "        w[6][0] = w6\n",
    "        bias = b\n",
    "    return [w,bias]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneVsAllTrain(X,y,alpha,iterations):\n",
    "    np.random.seed(44) \n",
    "    w = np.random.rand(7,1) #Weight matrix with random values 7*1 matrix\n",
    "    #w[0][0] = w[1][0] = w[2][0] = w[3][0] = w[4][0] = w[5][0] = w[6][0] = 0.0\n",
    "    bias = 1\n",
    "    \n",
    "    y1 = y2 = y3 = np.zeros(shape = (y.shape[0],1))\n",
    "    #Model - 1\n",
    "    for index_target,target in enumerate(y):\n",
    "        if target == 2.0 or target == 3.0 :\n",
    "            y1[index_target][0] = 0.0\n",
    "        elif target == 1.0:\n",
    "            y1[index_target][0] = 1.0\n",
    "    \n",
    "    w = np.random.rand(7,1)\n",
    "    bias = 1\n",
    "    parameters = logisticRegression(X,y1,w,bias,alpha,iterations)\n",
    "    model1_w = parameters[0]\n",
    "    model1_bias = parameters[1]\n",
    "    #Model - 2\n",
    "    for index_target,target in enumerate(y):\n",
    "        if target == 1.0 or target == 3.0 :\n",
    "            y2[index_target][0] = 0.0\n",
    "        elif target == 2.0:\n",
    "            y2[index_target][0] = 1.0\n",
    "        \n",
    "    \n",
    "    w = np.random.rand(7,1)\n",
    "    bias = 1\n",
    "    parameters = logisticRegression(X,y2,w,bias,alpha,iterations)\n",
    "    model2_w = parameters[0]\n",
    "    model2_bias = parameters[1]\n",
    "    \n",
    "    #Model - 3\n",
    "    for index_target,target in enumerate(y):\n",
    "        if target == 1.0 or target == 2.0 :\n",
    "            y3[index_target][0] = 0.0\n",
    "        elif target == 3.0:\n",
    "            y3[index_target][0] = 1.0\n",
    "    \n",
    "    w = np.random.rand(7,1)\n",
    "    bias = 1\n",
    "    parameters = logisticRegression(X,y3,w,bias,alpha,iterations)\n",
    "    model3_w = parameters[0]\n",
    "    model3_bias = parameters[1]\n",
    "\n",
    "    return [model1_w,model1_bias,model2_w,model2_bias,model3_w,model3_bias]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneVsAllTest(models,X,y):\n",
    "    y_predicted = []\n",
    "    model1_w = models[0]\n",
    "    model1_bias = models[1]\n",
    "    model2_w = models[2]\n",
    "    model2_bias = models[3]\n",
    "    model3_w = models[4]\n",
    "    model3_bias = models[5]\n",
    "    for index in range(y.shape[0]):\n",
    "        h1 = hypothesis(X[index],model1_w,model1_bias)\n",
    "        h2 = hypothesis(X[index],model2_w,model2_bias)\n",
    "        h3 = hypothesis(X[index],model3_w,model3_bias)\n",
    "        h = [h1,h2,h3]\n",
    "        h = np.asarray(h)\n",
    "        predicted_class = np.argmax(h) + 1\n",
    "        y_predicted.append(predicted_class)\n",
    "    return y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusionMatrix(y_test,y_predicted) :\n",
    "    u11 = u12 = u13 = u21 = u22 = u23 = u31 = u32 = u33 = 0\n",
    "    for index in range(y_test.shape[0]):\n",
    "        if y_test[index][0] == 1 :\n",
    "            if y_predicted[index] == 1:\n",
    "                u11 += 1\n",
    "            elif y_predicted[index] == 2:\n",
    "                u12 += 1\n",
    "            else:\n",
    "                u13 += 1\n",
    "        elif y_test[index][0] == 2:\n",
    "            if y_predicted[index] == 1:\n",
    "                u21 += 1\n",
    "            elif y_predicted[index] == 2:\n",
    "                u22 += 1\n",
    "            else:\n",
    "                u23 += 1\n",
    "        elif y_test[index][0] == 3:\n",
    "            if y_predicted[index] == 1:\n",
    "                u31 += 1\n",
    "            elif y_predicted[index] == 2:\n",
    "                u32 += 1\n",
    "            else:\n",
    "                u33 += 1\n",
    "    print(\"Confusion Matrix is :\")\n",
    "    print(u11,\" \",u12,\" \",u13)\n",
    "    print(u21,\" \",u22,\" \",u23)\n",
    "    print(u31,\" \",u32,\" \",u33)\n",
    "    \n",
    "    IA_class1 = (float(u11)/float(u11 + u12 + u13))*100\n",
    "    IA_class2 = (float(u22)/float(u21 + u22 + u23))*100\n",
    "    IA_class3 = (float(u33)/float(u31 + u32 + u33))*100\n",
    "    Overall_Acc = (float(u11 + u22 + u33)/float(u11 + u12 + u13 + u21 + u22 + u23 + u31 + u32 + u33))*100\n",
    "    \n",
    "    print(\"Individual Accuracy of class 1 is : \",IA_class1,\"%\")\n",
    "    print(\"Individual Accuracy of class 2 is : \",IA_class2,\"%\")\n",
    "    print(\"Individual Accuracy of class 3 is : \",IA_class3,\"%\")\n",
    "    print(\"Overall Accuracy is : \",Overall_Acc,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "valueArray = df.to_numpy()\n",
    "np.random.shuffle(valueArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Partition data set into 5 subsets\n",
    "subset1 = valueArray[0:30,0:]\n",
    "subset2 = valueArray[30:60,0:]\n",
    "subset3 = valueArray[60:90,0:]\n",
    "subset4 = valueArray[90:120,0:]\n",
    "subset5 = valueArray[120:150,0:]\n",
    "subsets = [subset1,subset2,subset3,subset4,subset5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "FOLD :  1 \n",
      "\n",
      "\n",
      "Confusion Matrix is :\n",
      "10   1   0\n",
      "2   3   8\n",
      "0   0   6\n",
      "Individual Accuracy of class 1 is :  90.9090909090909 %\n",
      "Individual Accuracy of class 2 is :  23.076923076923077 %\n",
      "Individual Accuracy of class 3 is :  100.0 %\n",
      "Overall Accuracy is :  63.33333333333333 %\n",
      "\n",
      "\n",
      "FOLD :  2 \n",
      "\n",
      "\n",
      "Confusion Matrix is :\n",
      "10   0   0\n",
      "4   2   2\n",
      "0   3   9\n",
      "Individual Accuracy of class 1 is :  100.0 %\n",
      "Individual Accuracy of class 2 is :  25.0 %\n",
      "Individual Accuracy of class 3 is :  75.0 %\n",
      "Overall Accuracy is :  70.0 %\n",
      "\n",
      "\n",
      "FOLD :  3 \n",
      "\n",
      "\n",
      "Confusion Matrix is :\n",
      "6   2   0\n",
      "0   5   4\n",
      "1   3   9\n",
      "Individual Accuracy of class 1 is :  75.0 %\n",
      "Individual Accuracy of class 2 is :  55.55555555555556 %\n",
      "Individual Accuracy of class 3 is :  69.23076923076923 %\n",
      "Overall Accuracy is :  66.66666666666666 %\n",
      "\n",
      "\n",
      "FOLD :  4 \n",
      "\n",
      "\n",
      "Confusion Matrix is :\n",
      "12   0   0\n",
      "3   5   2\n",
      "0   1   7\n",
      "Individual Accuracy of class 1 is :  100.0 %\n",
      "Individual Accuracy of class 2 is :  50.0 %\n",
      "Individual Accuracy of class 3 is :  87.5 %\n",
      "Overall Accuracy is :  80.0 %\n",
      "\n",
      "\n",
      "FOLD :  5 \n",
      "\n",
      "\n",
      "Confusion Matrix is :\n",
      "9   0   0\n",
      "2   5   3\n",
      "0   5   6\n",
      "Individual Accuracy of class 1 is :  100.0 %\n",
      "Individual Accuracy of class 2 is :  50.0 %\n",
      "Individual Accuracy of class 3 is :  54.54545454545454 %\n",
      "Overall Accuracy is :  66.66666666666666 %\n"
     ]
    }
   ],
   "source": [
    "testData = np.zeros(shape = (30,8))\n",
    "for testing_index in range(len(subsets)):\n",
    "    print(\"\\n\\nFOLD : \",testing_index+1,\"\\n\\n\")\n",
    "    trainData = np.zeros(shape = (0,8))\n",
    "    testData = subsets[testing_index]\n",
    "    for training_index in range(len(subsets)):\n",
    "        if training_index == testing_index:\n",
    "            continue\n",
    "        trainData = np.concatenate((trainData,subsets[training_index]))\n",
    "    X_train , X_test = trainData[0:,0:7] , testData[0:,0:7]\n",
    "    X_train = (X_train - X_train.mean())/X_train.std()\n",
    "    X_test = (X_test - X_test.mean())/X_test.std()\n",
    "    y_train , y_test = trainData[0:,7:] , testData[0:,7:]\n",
    "    #Use logistic regression function on this trainingData\n",
    "    models = oneVsAllTrain(X_train,y_train,0.75,5000)\n",
    "    #Find accuracy on this testingData\n",
    "    y_predicted = oneVsAllTest(models,X_test,y_test)\n",
    "    confusionMatrix(y_test,y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
