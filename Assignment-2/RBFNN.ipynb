{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math  \n",
    "from sklearn.cluster import KMeans\n",
    "from pandas import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import getData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernelFunction(XminusMu, sigmaK, name):\n",
    "    phi = 0.0\n",
    "    if sigmaK == 0: sigmaK = 1e-10 #This step is because when one of the cluster has only value that means its sigma=0 \n",
    "    if name == \"Gaussian\":\n",
    "        phi = np.exp((-0.5 * (XminusMu**2))/(sigmaK**2))\n",
    "    elif name == \"Multiquadratic\":\n",
    "        phi = (XminusMu**2 + sigmaK**2)**0.5 \n",
    "    elif name == \"Linear\":\n",
    "        phi = XminusMu\n",
    "    return phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_X, train_Y, K, name):\n",
    "    m = train_X.shape[0]\n",
    "    classes = train_Y.shape[1]\n",
    "    # K Means on train_X\n",
    "    # Number of hidden neurons = Number of clusters K\n",
    "    # mu(k) = centroid of kth cluster (k = 1 to K)\n",
    "    kmeans = KMeans(n_clusters = K, max_iter=1000, random_state = 0).fit(train_X) \n",
    "    mu = kmeans.cluster_centers_\n",
    "    labels = kmeans.predict(train_X)\n",
    "    # sigma(k) = 1/m(k) * sum over i=1 to m(k) [||X(i) - Mu(k)||]\n",
    "    sigma = np.zeros(K)\n",
    "    for k in range(K):\n",
    "        clusterK = train_X[(labels == k)]\n",
    "        mK = len(clusterK)\n",
    "        summation = 0.0\n",
    "        for i in range(mK):\n",
    "            summation = summation + np.linalg.norm(clusterK[i]-mu[k],1)\n",
    "        sigma[k] = (1.0/mK) * summation\n",
    "    # Evaluate hidden layer matrix H m*K\n",
    "    H = np.ndarray((m, K))\n",
    "    # H[i][k] = phi(||X(i) - mu(k)||)\n",
    "    for i in range(m):\n",
    "        for k in range(K):\n",
    "            XminusMu = np.linalg.norm(train_X[i] - mu[k], 1)\n",
    "            H[i][k] = kernelFunction(XminusMu, sigma[k], name)\n",
    "    # Weight matrix W = H^-1 Y () m*K.K*classes = m*classes\n",
    "    W = np.dot(np.linalg.pinv(H),train_Y)\n",
    "    #Return Values\n",
    "    return [W, mu, sigma, name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_X, test_Y, W, K, mu, sigma, name):\n",
    "    # Evaluate hidden layer matrix H m*K\n",
    "    m = test_X.shape[0]\n",
    "    H = np.zeros((m, K))\n",
    "    # H[i][k] = phi(||X(i) - mu(k)||)\n",
    "    for i in range(m):\n",
    "        for k in range(K):\n",
    "            XminusMu = np.linalg.norm(test_X[i] - mu[k], 1)\n",
    "            H[i][k] = kernelFunction(XminusMu, sigma[k], name)\n",
    "    # Y_predicted = H.dot(W)\n",
    "    Y_predicted = H.dot(W)\n",
    "    # MaxIndex of Y_predicted[i] is prediction for test_X[i] and compare with test_Y[i]\n",
    "     \n",
    "    count = 0\n",
    "    TrueZeros = TrueOnes = FalseZeros = FalseOnes = 0\n",
    "    for i in range(m):\n",
    "        actualClass = np.argmax(test_Y[i])\n",
    "        predictedClass = np.argmax(Y_predicted[i])\n",
    "        if actualClass == predictedClass:\n",
    "            count += 1\n",
    "            if actualClass == 0:\n",
    "                TrueZeros += 1\n",
    "            else:\n",
    "                TrueOnes += 1\n",
    "        else:\n",
    "            if actualClass == 0:\n",
    "                FalseZeros += 1\n",
    "            else:\n",
    "                FalseOnes += 1\n",
    "    conf_mat = ([[TrueZeros, FalseZeros], [FalseOnes, TrueOnes]])\n",
    "    print(\"Accuracy:-\")\n",
    "    print(count/m*100)\n",
    "    print(\"Confusion Matrix:-\")\n",
    "    print(DataFrame(conf_mat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = getData('data.mat')\n",
    "#Holdout method -> \n",
    "def holdout(X, Y, train_percent, K, name):\n",
    "    train_size = int(train_percent*X.shape[0])\n",
    "    train_X = X[:train_size,:]\n",
    "    test_X = X[train_size:,:]\n",
    "    train_Y = Y[:train_size,:]\n",
    "    test_Y = Y[train_size:,:]\n",
    "    [W, mu, sigma, name] = train(train_X, train_Y, K, name)\n",
    "    return test(test_X, test_Y, W, K, mu, sigma, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70-30 Holdout Method :-\n",
      "\n",
      "Gaussian Function :-\n",
      "Accuracy:-\n",
      "93.33333333333333\n",
      "Confusion Matrix:-\n",
      "     0    1\n",
      "0  287   22\n",
      "1   21  315\n",
      "\n",
      "Multiquadratic Function :-\n",
      "Accuracy:-\n",
      "91.31782945736434\n",
      "Confusion Matrix:-\n",
      "     0    1\n",
      "0  282   27\n",
      "1   29  307\n",
      "\n",
      "Linear Function :-\n",
      "Accuracy:-\n",
      "91.62790697674419\n",
      "Confusion Matrix:-\n",
      "     0    1\n",
      "0  286   23\n",
      "1   31  305\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"70-30 Holdout Method :-\")\n",
    "print()\n",
    "print(\"Gaussian Function :-\")\n",
    "holdout(X, Y, 0.7, 350, \"Gaussian\")\n",
    "print()\n",
    "print(\"Multiquadratic Function :-\")\n",
    "holdout(X, Y, 0.7, 350, \"Multiquadratic\")\n",
    "print()\n",
    "print(\"Linear Function :-\")\n",
    "holdout(X, Y, 0.7, 350, \"Linear\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 fold cross validation\n",
    "from sklearn.model_selection import KFold\n",
    "def k_fold(k, name):\n",
    "    K = k\n",
    "    kf = KFold(n_splits=5)\n",
    "    kf.get_n_splits(X)\n",
    "    fold = 0\n",
    "    avg_accuracy = 0\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        fold += 1\n",
    "        train_X, test_X = X[train_index], X[test_index]\n",
    "        train_Y, test_Y = Y[train_index], Y[test_index]\n",
    "        instances = train_X.shape[0]\n",
    "        classes = test_Y.shape[1]\n",
    "        features = train_X.shape[1]\n",
    "        [W, mu, sigma, name] = train(train_X, train_Y, K, name)\n",
    "        print(\"Fold %d :- \"%fold)\n",
    "        print()\n",
    "        test(test_X, test_Y, W, K, mu, sigma, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 :- \n",
      "\n",
      "Accuracy:-\n",
      "62.093023255813954\n",
      "Confusion Matrix:-\n",
      "     0    1\n",
      "0  154   60\n",
      "1  103  113\n",
      "Fold 2 :- \n",
      "\n",
      "Accuracy:-\n",
      "60.46511627906976\n",
      "Confusion Matrix:-\n",
      "     0    1\n",
      "0  144   61\n",
      "1  109  116\n",
      "Fold 3 :- \n",
      "\n",
      "Accuracy:-\n",
      "63.72093023255814\n",
      "Confusion Matrix:-\n",
      "     0    1\n",
      "0  162   74\n",
      "1   82  112\n",
      "Fold 4 :- \n",
      "\n",
      "Accuracy:-\n",
      "64.1025641025641\n",
      "Confusion Matrix:-\n",
      "     0    1\n",
      "0  152   64\n",
      "1   90  123\n",
      "Fold 5 :- \n",
      "\n",
      "Accuracy:-\n",
      "63.4032634032634\n",
      "Confusion Matrix:-\n",
      "     0    1\n",
      "0  144   60\n",
      "1   97  128\n"
     ]
    }
   ],
   "source": [
    "k_fold(5, \"Gaussian\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
